{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b6cacb",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "from typing import Dict, List, Tuple\n",
    "from collections import defaultdict\n",
    "import logging\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5472b7d9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def is_colab() -> None:\n",
    "  try:\n",
    "    import google.colab\n",
    "    return True\n",
    "  except ImportError:\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a9e0f1",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class DexterDialogueProcessor:\n",
    "  def __init__(self, transcript_path: str = \"data/dexter_transcripts.json\"):\n",
    "    if is_colab():\n",
    "      log_path = \"/content/darkly_speaking_dexter/logs\"\n",
    "      transcript_path = \"/content/darkly_speaking_dexter/\" + transcript_path\n",
    "    else:\n",
    "      log_path = \"./logs\"\n",
    "\n",
    "    self.transcript_path = Path(transcript_path)\n",
    "    self.dexter_dialogues: List[Dict] = []\n",
    "    self.context_windows: List[Tuple[List[str], str]] = []\n",
    "    self.training_pairs: List[Dict] = []\n",
    "    \n",
    "    logging.basicConfig(\n",
    "      level=logging.INFO,\n",
    "      format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "      handlers=[\n",
    "        logging.FileHandler(log_path + '/dialogue_processor.log'),\n",
    "        logging.StreamHandler()\n",
    "      ]\n",
    "    )\n",
    "    self.logger = logging.getLogger(__name__)\n",
    "\n",
    "  def load_transcripts(self) -> None:\n",
    "    \"\"\"Load and validate transcript data.\"\"\"\n",
    "    with open(self.transcript_path, 'r', encoding='utf-8') as f:\n",
    "      transcript_obj = json.load(f)\n",
    "        \n",
    "    if not isinstance(transcript_obj, dict) or 'episodes' not in transcript_obj:\n",
    "      raise ValueError(\"Invalid transcript format\")\n",
    "        \n",
    "    self.transcript_obj = transcript_obj\n",
    "  \n",
    "  def extract_dexter_dialogue(self) -> List[Dict]:\n",
    "    \"\"\"Extract dialogue pairs where Dexter responds to someone.\"\"\"\n",
    "    dexter_dialogues = []\n",
    "    \n",
    "    for episode_obj in self.transcript_obj['episodes']:\n",
    "      dialogue = episode_obj['dialogue']\n",
    "      \n",
    "      for i in range(len(dialogue)-1):\n",
    "        current = dialogue[i] \n",
    "        next_line = dialogue[i+1]\n",
    "      \n",
    "        if (\n",
    "          'speaker' not in current \n",
    "          or 'text' not in current\n",
    "          or current['speaker'] is None\n",
    "          or current['text'] is None\n",
    "          or not current['speaker'].strip()\n",
    "          or not current['text'].strip()\n",
    "        ): continue\n",
    "        \n",
    "        if current['speaker'].upper() != 'DEXTER' and next_line['speaker'].upper() == 'DEXTER':\n",
    "          # pdb.set_trace()\n",
    "          processed_dialogue_obj = {\n",
    "            'user_message': current['text'],\n",
    "            'dexter_response': next_line['text'],\n",
    "            'episode_title': episode_obj['title'],\n",
    "            'line_number': next_line['line_number']\n",
    "          }\n",
    "          dexter_dialogues.append(processed_dialogue_obj)\n",
    "    \n",
    "    self.dexter_dialogues = dexter_dialogues\n",
    "    return dexter_dialogues\n",
    "\n",
    "  def create_training_pairs(self) -> List[Dict]:\n",
    "    \"\"\"Create input/output pairs for training.\"\"\"\n",
    "    training_pairs = []\n",
    "    \n",
    "    for dialogue_obj in self.dexter_dialogues:\n",
    "      # Remove speaker tags from any input text\n",
    "      # pdb.set_trace()\n",
    "      input_text = dialogue_obj['dexter_response']\n",
    "      if ':' in input_text:\n",
    "        input_text = input_text.split(':', 1)[1].strip()\n",
    "\n",
    "      training_pair_obj = {\n",
    "        'input': input_text,\n",
    "        'output': dialogue_obj['dexter_response'],\n",
    "        'metadata': {\n",
    "          'episode': dialogue_obj['episode_title'],\n",
    "          'line_number': dialogue_obj['line_number']\n",
    "        }\n",
    "      }\n",
    "      \n",
    "      training_pairs.append(training_pair_obj)\n",
    "    self.training_pairs = training_pairs\n",
    "    return training_pairs\n",
    "  \n",
    "  def get_stats(self) -> Dict:\n",
    "    \"\"\"Get basic statistics about the processed data.\"\"\"\n",
    "    if not self.dexter_dialogues:\n",
    "      return {}\n",
    "\n",
    "    stats_obj = {\n",
    "      'total_dialogues': len(self.dexter_dialogues),\n",
    "      'avg_dialogue_length': sum(len(d['dexter_response'].split()) for d in self.dexter_dialogues) / len(self.dexter_dialogues),\n",
    "      'unique_episodes': len(set(d['episode_title'] for d in self.dexter_dialogues)),\n",
    "      'dialogues_with_context': sum(1 for d in self.dexter_dialogues if d['user_message'])\n",
    "    }\n",
    "    \n",
    "    return stats_obj\n",
    "  \n",
    "  def create_training_samples(self) -> List[Dict]:\n",
    "    \"\"\"Format chat pairs for model training.\"\"\"\n",
    "    training_samples = []\n",
    "    \n",
    "    for pair in self.training_pairs:\n",
    "      # Simple input/output format for chatbot\n",
    "      sample = {\n",
    "        'input': pair['input'],\n",
    "        'output': pair['output'],\n",
    "        'metadata': pair['metadata']\n",
    "      }\n",
    "      training_samples.append(sample)\n",
    "    \n",
    "    return training_samples\n",
    "  \n",
    "  def save_training_data(self, output_path: str = \"data/chatbot_training_data.json\") -> None:\n",
    "    \"\"\"Save processed training pairs to JSON.\"\"\"\n",
    "    training_pairs = self.create_training_pairs()\n",
    "    training_samples = self.create_training_samples()\n",
    "\n",
    "    stats_obj = self.get_stats()\n",
    "    \n",
    "    output_obj = {\n",
    "      'metadata': {\n",
    "        'stats': stats_obj,\n",
    "        'source': str(self.transcript_path)\n",
    "      },\n",
    "      'training_pairs': training_pairs,\n",
    "      'samples': training_samples\n",
    "    }\n",
    "    output_path = \"/content/darkly_speaking_dexter/\" + output_path\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "      json.dump(output_obj, f, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1166ce3",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "  processor = DexterDialogueProcessor()\n",
    "  print(dir(processor))  # Add this line to see what methods are available\n",
    "  processor.load_transcripts()\n",
    "  processor = DexterDialogueProcessor()\n",
    "  processor.load_transcripts()\n",
    "  processor.extract_dexter_dialogue()\n",
    "  processor.save_training_data()\n",
    "  print(processor.get_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac10176",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "  main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
