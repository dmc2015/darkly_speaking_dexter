{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5264092",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "from typing import Dict, List\n",
    "import logging\n",
    "from transformers import GPT2Tokenizer\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e407df",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def is_colab():\n",
    "    try:\n",
    "        import google.colab\n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35ac18a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class DexterGPT2Preprocessor:\n",
    "    def __init__(self, training_data_path: str = \"data/chatbot_training_data.json\"):\n",
    "        if is_colab():\n",
    "            log_path = \"/content/darkly_speaking_dexter/logs\"\n",
    "            training_data_path = \"/content/darkly_speaking_dexter/\" + training_data_path\n",
    "        else:\n",
    "            log_path = \"./logs\"\n",
    "        \n",
    "        self.training_data_path = Path(training_data_path)\n",
    "        self.tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "        self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Setup logging\n",
    "        logging.basicConfig(\n",
    "            level=logging.INFO,\n",
    "            format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "            handlers=[logging.FileHandler(log_path + \"/gpt_processing.log\"), logging.StreamHandler()],\n",
    "        )\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "\n",
    "    def load_training_data(self) -> List[Dict]:\n",
    "        \"\"\"Load the chat training samples.\"\"\"\n",
    "        with open(self.training_data_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        return data['samples']\n",
    "  \n",
    "    def _clean_text(self, text: str) -> str:\n",
    "        \"\"\"Clean text of speaker tags and artifacts.\"\"\"\n",
    "        import re\n",
    "        \n",
    "        # Remove speaker tags\n",
    "        text = re.sub(r'[A-Z]+:\\s*', '', text)\n",
    "        \n",
    "        # Remove special tokens\n",
    "        text = re.sub(r'<\\|.*?\\|>', '', text)\n",
    "        text = re.sub(r'\\|\\|.*?\\|\\|', '', text)\n",
    "        \n",
    "        # Remove formatting artifacts\n",
    "        text = re.sub(r'\\|\\s*\\|', '', text)\n",
    "        text = re.sub(r'\\s*\\|\\s*', ' ', text)\n",
    "        \n",
    "        # Clean up whitespace\n",
    "        text = ' '.join(text.split())\n",
    "        \n",
    "        return text.strip()\n",
    "    \n",
    "    def format_for_gpt2(self, samples: List[Dict]) -> List[str]:\n",
    "        \"\"\"Convert chat samples into GPT2 format.\"\"\"\n",
    "        formatted_texts = []\n",
    "        for sample in samples:\n",
    "            # Remove speaker tags and simplify format\n",
    "            clean_input = self._clean_text(sample['input'])\n",
    "            clean_output = self._clean_text(sample['output'])\n",
    "            # Use a simpler format without speaker tags\n",
    "            formatted_text = f\"Input: {clean_input} Output: {clean_output}{self.tokenizer.eos_token}\"\n",
    "            formatted_texts.append(formatted_text)\n",
    "        return formatted_texts\n",
    "    \n",
    "    def save_formatted_data(self, formatted_texts: List[str], output_path: str = \"data/gpt2_training_data.json\"):\n",
    "        \"\"\"Save the formatted texts.\"\"\"\n",
    "        output_obj = {\n",
    "            'formatted_texts': formatted_texts,\n",
    "            'metadata': {\n",
    "                'total_samples': len(formatted_texts),\n",
    "                'tokenizer': 'gpt2'\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        output_path = \"/content/darkly_speaking_dexter/\" + output_path\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(output_obj, f, indent=2)\n",
    "        \n",
    "        self.logger.info(f\"Saved {len(formatted_texts)} formatted samples to {output_path}\")\n",
    "    \n",
    "    def process(self):\n",
    "        \"\"\"Run the full preprocessing pipeline.\"\"\"\n",
    "        samples = self.load_training_data()\n",
    "        formatted_texts = self.format_for_gpt2(samples)\n",
    "        self.save_formatted_data(formatted_texts)\n",
    "        return formatted_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9d6c28",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    preprocessor = DexterGPT2Preprocessor()\n",
    "    preprocessor.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a125fc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
